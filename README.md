# OttomanPages

The digitization of historical documents plays a vital role in preserving and
enhancing access to cultural heritage. Among these, Ottoman-era manuscripts
and printed materials pose distinct challenges due to their diverse scripts,
complex layouts, and varying physical degradation. Effective page segmentation—crucial 
for tasks such as optical character recognition (OCR), handwriting
transcription, and layout reconstruction—is particularly difficult for Ottoman
documents, which often contain multi-column arrangements, decorative calligraphy, 
and intertwined text regions. While modern segmentation techniques have
shown success on Latin-script documents, their applicability to Ottoman Turkish
remains limited. To address this gap, we introduce OttomanPages, a specialized
framework for segmenting historical Ottoman document images. Our approach
leverages a hybrid architecture combining traditional image processing with deep
learning models and domain-specific heuristics to effectively differentiate between
textual and non-textual components. We also present a newly curated and
annotated dataset of Ottoman manuscripts and printed texts to benchmark seg￾mentation performance. 
Experimental evaluations demonstrate that our method
outperforms generic techniques in preserving layout structure and improving
downstream processing accuracy. This work provides both a methodological con￾tribution and a 
foundational resource for future research in historical document
analysis, particularly in underrepresented non-Latin scripts such as Ottoman
Turkish.
